---
title: "Anacondaを使ってPythonの環境構築をする"
emoji: "🙌"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [Python,Anaconda,MachineLearning,Spyder,JupyterNotebook]
published: false
Author: yuuma
---

&nbsp;

:::message
今回の記事に対応する動画は以下からアクセスすることができます｡
__[Anacondaを使ってPythonの環境構築をする導入 ～Spyder活用編](https://togotv.dbcls.jp/20231201.html)__
__[Anacondaを使ってPythonの仮想環境を構築する&データ解析をする](https://togotv.dbcls.jp/20231202.html)__
:::
https://youtu.be/UdexSPlyjLI
https://youtu.be/mQiEDdr3bwA
:::message alert
本動画ではAnacondaを用いたPythonの環境構築を行います｡
__PipでPythonをマシンに導入している場合は、ライブラリが競合する恐れがあります。Anacondaをインストールする前にPip環境を削除することをおすすめします｡__
:::


&nbsp;

## はじめに

:::message
__本記事の対象となる方__

■ Pythonをローカルマシンに構築したい人
■ Pythonのライブラリをラクに管理したい人
■ Pythonの仮想環境を構築したい人
■ Anacondaを使って機械学習をしたい人
:::

この記事では、以下の2点をご紹介します。
__(1) WindowsマシンにAnacondaをインストールする__
__(2) Anacondaでインストールされるアプリ（Spyder、Jupyter Notebook）を使う__
__(3) Spyder特有の機能紹介と、Spyderを用いてデバッグ方法を行う__
__(4) Anacondaで仮想環境を構築する__
__(5) Anacondaでデータ解析、機械学習を行う__

&nbsp;
### Anacondaを使うメリット

本記事を参考にすることで、ローカルマシンにAnacondaをインストールし、Pythonの環境構築を行うことができます。

Anacondaは、__データ分析や科学計算に特化したPythonの統合開発環境__ を提供しています。__良く用いられるライブラリが同時にインストールされる__ ため、Anacondaをインストールするだけで、ほとんどの作業をすぐに始めることができます。

特に、高機能なエディタである __Spyder__ や、ノートブック形式でプログラムを作成できる __Jupyter Notebook__ を使うことで、データ分析や機械学習をより効率的に行うことができます。
さらに、__Anaconda Navigator__ というGUIツールによって、ライブラリの管理、仮想環境の作成・管理を直感的に行うこともできます。

&nbsp;

## Anacondaをインストールする
今回はAnacondaをWindowsマシンにインストールします。Anacondaは、Windows、Mac、Linuxの各OSに対応しています。インストーラは、[Anaconda公式サイトのダウンロードページ](https://www.anaconda.com/download)からダウンロードすることができます。
![install](/images/20231130/20231130_01.png =500x)
*Anacondaのインストールサイト*
Anacondaのインストーラをダウンロードしたら、インストーラを起動して、インストールを行います。インストールの際の注意点は以下の通りです：
:::message
- インストール先のパスには、__半角英数字と "_"（アンダーバー）および "-"（ハイフン）__ 以外の文字を含めないようにしてください。
- `Install for:`の画面では、__`Just Me`をおすすめします。__`All Users`は、同じマシンを使っている別のユーザーの環境に影響を与える可能性があります。
- `Advanced Installation Options`は既定のままで問題ありません。
- `Add Anaconda to my PATH environment variable`は、__チェックを入れなくても構いません。__ チェックを入れた場合は、Anacondaのコマンドをコマンドプロンプトから実行できるようになります。入れない場合は、Anaconda Navigatorから実行することになります。
:::

## Anaconda Navigatorから各アプリケーションを使う
Anacondaをインストールすると、__Anaconda Navigator__ というGUIツールがインストールされます。Jupyter NotebookやSpyderなどのアプリケーションは、ここから起動します。Anaconda Navigatorを起動するには、スタートメニューからAnaconda Navigatorを選択します。

![anaconda navigator](/images/20231130/20231130_02.png)
*Anaconda Navigatorの起動画面*

`Launch`ボタンから各アプリケーションを起動することができます。また、`Environments`タブから、仮想環境の作成や管理を行うことができます。仮想環境については後述します。

### Jupyter Notebookを起動する
Jupyter Notebookは、__ブラウザ上でPythonプログラムを実行できるアプリケーション__ です。ファイルやフォルダの作成方法は動画を参照してください。

`New`から`Python 3 (ipykernel)`を選択すると、Notebookファイルを作成できます。Notebookファイルは、拡張子が`.ipynb`のファイルです。
![jupyter notebook](/images/20231130/20231130_03.png)
*フォルダ名やファイル名は`Rename`から変更可能*

Notebookファイルでは、`In [ ]:`の部分にPythonのコードを入力して、`Shift + Enter`を押すと、そのコードが実行されます。`In [ ]:`の部分には、実行した順番に番号が振られます。
また、`+`ボタンから、新しいセルを追加することができます。セルの種類は、`Code`と`Markdown`の2種類があります：

- `Code`はPythonのコードを実行できる。
- `Markdown`はテキストを __Markdown記法__ で記述できる。

Anacondaのインストール時点で、科学計算やデータ分析に必要なライブラリがインストールされているため、すぐにデータ分析を始めることができます。例えば、以下のコードを実行すると、Notebook上にグラフが表示されます。

```python:グラフを表示するコード
import numpy as np
import matplotlib.pyplot as plt

x=np.linspace(0,10,100)
plt.plot(x,np.sin(x))
```

### Spyderを起動する
Spyderは、__高機能なPythonの統合開発環境__ です。変数の中身を確認したり、デバッグを行うことができます。また、関数や変数の補完機能や、リアルタイムでのエラー表示も備えており、プログラムの作成を効率化することができます。

## Spyderに特有の機能について
Spyderには、以下のような特徴的な機能があります：
- 変数の中身を確認できる。
- グラフを履歴として一時的に保存できる。
- デバッグを行うことができる。

### 変数エクスプローラーとプロット機能
動画内で詳しく説明していますが、Spyder右上のウィンドウにある __変数エクスプローラー (Variable Explorer)__ タブから、変数の中身を確認することができます。また、__プロット (Plots)__ タブから、グラフを履歴として一時的に保存することができます。これらの機能は、データ分析を行う際に非常に便利です。

![spyder](/images/20231130/20231130_04.png =1000x)
*変数エクスプローラーで配列の中身を確認できる。*
![spyder](/images/20231130/20231130_05.png =1000x)
*プロットを独立したウィンドウで確認できる。プロット履歴も残っている。*

### Pythonプログラムのデバッグを行う
Spyderには、プログラムを行単位で実行したり、任意の場所で実行を一時停止するデバッグ機能がデフォルトで存在します。
__エディター上部の青いボタン群__ がデバッグ機能です。青いボタンには、左から以下のような機能があります：
- デバッグを実行する
- 1行ずつ実行する
- 関数内へのステップイン
- 関数の最後まで実行する
- 次のブレークポイントまで実行する
- デバッグを中断する

これらの機能を用途によって使い分けることができます。
![spyder](/images/20231130/20231130_06.png =1000x)
*デバッグ中に変数エクスプローラーを用いると、プログラムの実行に伴う変数の更新がわかる。*

:::message
ここまでが __[Anacondaを使ってPythonの環境構築をする 導入編～Spyder](https://togotv.dbcls.jp/20230301.html)__ の内容です。
:::

## 仮想環境を構築する
Anaconda Navigatorから仮想環境を作成・管理することができます。仮想環境とは、__Pythonのライブラリを独立した環境にインストールすること__ です。仮想環境を使うことで、ライブラリのバージョンを切り替えたり、ライブラリの競合を防ぐことができます。
Anaconda Navigatorの`Environments`タブから、仮想環境の作成・管理を行うことができます。仮想環境の作成方法は動画を参照してください。

![anaconda navigator](/images/20231130/20231130_07.png)
*作成した仮想環境の情報は`Environments`タブから確認できる。*

::: message alert
numpyやmatplotlibなどのライブラリは、Anacondaをインストールした時点でbase(root)環境にはインストールされていますが、__仮想環境ではインストールされていません。__ 
仮想環境を作成したら、必要なライブラリをインストールする必要があります。
:::

### 仮想環境でPythonを実行する
仮想環境を作成したら、その環境でPythonを実行することができます。Anaconda Navigatorの`Home`タブから、`All apprications` on `test` を選択すると、`test`環境内で各アプリケーションを起動することができます。
Spyderを起動したい場合は、`test`環境内にSpyderをインストールする必要があります。先ほど`Launch`と表示されていたものが、`Install`に変化していることを確認してください。

![anaconda navigator](/images/20231130/20231130_08.png)
*仮想環境を選択すると、その環境でアプリケーションを起動できる。*

![spyder](/images/20231130/20231130_09.png =1000x)
*作成した仮想環境では、numpyやmatplotlibなどのライブラリはインストールされていない。*

### 仮想環境にライブラリをインストールする
Anaconda Navigatorの`Environments`タブから、仮想環境にライブラリをインストールすることができます。`test`環境内で、`numpy`と`matplotlib`をインストールするには、`test`環境を選択して、`Installed`のタブを`Not installed`に変更し、`Search Packages`で`numpy`や、`matplotlib`を検索し、`Apply`を押します。

![anaconda navigator](/images/20231130/20231130_10.png)
*仮想環境にライブラリをインストールする。*

### Anaconda Promptを使って仮想環境を構築する
GUI環境のAnaconda Navigatorを使わずに、CUI環境の __Anaconda Prompt__ を使って仮想環境を構築することもできます。Anaconda Promptは、スタートメニューからAnaconda Promptを選択することで起動できます。コマンドプロンプトと同じように、コマンドを入力して実行することができます。

Anaconda Promptを使って仮想環境を構築するには、以下のコマンドを実行します：
```bash:Anaconda Prompt
conda create -n test python=3.6
```
`-n`オプションで、仮想環境の名前を指定します。`python=3.6`は、Pythonのバージョンを指定しています。
ライブラリのインストールもAnaconda Promptで行うことができます。例えば、`numpy`のインストールは、以下のコマンドを実行します：
```bash:Anaconda Prompt
conda install numpy
```
作成した環境一覧は、以下のコマンドで確認できます：
```bash:Anaconda Prompt
conda info -e
```
実行結果は以下のようになります：
```bash
# conda environments:
#
base                  *  C:\Users\yuuma\anaconda3
test                     C:\Users\yuuma\anaconda3\envs\test
```
baseが大元の環境で、testが作成した仮想環境です。`C:\Users\yuuma\anaconda3\envs\test`に仮想環境のフォルダが作成されていることがわかります。__"*"__（アスタリスク）が付いているのは、現在の環境がbaseであることを示しています。

仮想環境に切り替えるには、以下のコマンドを実行します：
```bash:Anaconda Prompt
activate test
```
`activate`コマンドを実行すると、プロンプトの先頭に`(test)`と表示されます。これは、現在の仮想環境が`test`であることを示しています。仮想環境を終了して、大元の環境(base)に戻るためには、以下のコマンドを実行します：
```bash:Anaconda Prompt
deactivate
```
これらのコマンドを使うことで、Anaconda Prompt上で仮想環境を構築することができますが、Anaconda Navigatorでも十分です。

![anaconda prompt](/images/20231130/20231130_11.png)
*Anaconda Promptで仮想環境の確認をし、`test`環境のactivateを行っている。*

## Anacondaでデータ解析、機械学習を行う
Anacondaで導入されたツールを用いてデータ分析を行ってみます。今回は仮想環境ではなく、base(root)環境で作業を行います。
### ネット上に公開されているZIPファイルからcsvファイルを抽出する
今回は、カリフォルニア大学のアーバイン校が管理・公開している機械学習データセットのリポジトリである[UCI Machine Learning Repository](http://archive.ics.uci.edu/)に展開されているデータを読み込みます。大学が公開しているため信頼性も高く研究者の間でも有名です。

まずは、必要なライブラリをインポートします。これらはAnacondaに最初から入っているライブラリです。

```python:ライブラリのインポート
# webからデータを取得したり、zipファイルを扱うためのライブラリ
import requests, zipfile
from io import StringIO
import io

# データを扱うためのライブラリ
import pandas as pd
```

次に、指定したurlからZIPファイルを読み込み、中身を展開します。
```python:urlからZIPファイルの読み込み、展開
# データがあるurlの指定
url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip'


# データをurlから取得する
r = requests.get(url, stream=True)


# zipfileを読み込み展開する
z = zipfile.ZipFile(io.BytesIO(r.content))
z.extractall()
```
展開されたファイル群は、実行しているPython（Notebook）ファイルと同じディレクトリに保存されます。そのうちの`student-mat.csv`を読み込みます。
```python:csvファイルの読み込み（うまくいかない例）
# csvファイルを読み込んで、DataFrame形式に変換する
student_data_math = pd.read_csv('student-mat.csv')
student_data_math.head(10) # 先頭10行を表示
```
しかし、このコードでは意図した通りのDataDrame形式に変換されていません。

![student_data_math](/images/20231130/20231130_12.png =1000x)
*カラムが分けられていないDataFrameとして変換される*
原因は、csvファイルの区切り文字が __セミコロン__ になっているためです。csvファイルの区切り文字を指定するには、`sep`オプションを使います。

```python:csvファイルの読み込み（修正版）
# csvファイルを読み込んで、DataFrame形式に変換する
student_data_math = pd.read_csv('student-mat.csv',sep=";") # 区切り文字を;に指定
student_data_math.head(10) # 先頭10行を表示
```
こうすることで、意図した通りのDataFrame形式に変換することができます。
![student_data_math](/images/20231130/20231130_13.png =1000x)
読み込んだデータのカラム情報は、DataFrameの`info()`メソッドで確認できます。
```python:カラム情報の確認
student_data_math.info()
```
```bash:実行結果
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 395 entries, 0 to 394
Data columns (total 33 columns):
 #   Column      Non-Null Count  Dtype 
---  ------      --------------  ----- 
 0   school      395 non-null    object
 1   sex         395 non-null    object
 2   age         395 non-null    int64 
 3   address     395 non-null    object
 4   famsize     395 non-null    object
 5   Pstatus     395 non-null    object
 6   Medu        395 non-null    int64 
 7   Fedu        395 non-null    int64 
 8   Mjob        395 non-null    object
 9   Fjob        395 non-null    object
 ︙    ︙　        ︙    ︙         ︙
 28  health      395 non-null    int64 
 29  absences    395 non-null    int64 
 30  G1          395 non-null    int64 
 31  G2          395 non-null    int64 
 32  G3          395 non-null    int64 
dtypes: int64(16), object(17)
memory usage: 102.0+ KB
```
`object`型は文字列、`int64`型は整数を表します。また、`describe()`メソッドを使うと、__各カラムの平均値や分散、最大値や最小値__ などの基本的な統計量を確認できます。
```python:統計量の確認
student_data_math.describe()
```
```bash:実行結果
              age        Medu        Fedu  ...          G1          G2          G3
count  395.000000  395.000000  395.000000  ...  395.000000  395.000000  395.000000
mean    16.696203    2.749367    2.521519  ...   10.908861   10.713924   10.415190
std      1.276043    1.094735    1.088201  ...    3.319195    3.761505    4.581443
min     15.000000    0.000000    0.000000  ...    3.000000    0.000000    0.000000
25%     16.000000    2.000000    2.000000  ...    8.000000    9.000000    8.000000
50%     17.000000    3.000000    2.000000  ...   11.000000   11.000000   11.000000
75%     18.000000    4.000000    3.000000  ...   13.000000   13.000000   14.000000
max     22.000000    4.000000    4.000000  ...   19.000000   19.000000   20.000000
```
このように、Anacondaで導入されたツールを用いることで、データの読み込みやその中身の確認を簡単に行うことができます。


### scikit-learnを使って機械学習を行う
最後に、scikit-learnを使って教師ありの機械学習を行います。scikit-learnは、__Pythonで機械学習を行うためのライブラリです。__ Anacondaには、scikit-learnがインストールされているため、すぐに機械学習を始めることができます。
機械学習の基礎については説明しませんが、Anacondaを用いると、事前準備なしに機械学習ができるということを紹介します。

scikit-learnには、load_breast_cancerと呼ばれるサンプルデータが公開されており、乳がんに関するデータがまとめられています。

複数の特徴量（data）から、陽性か陰性か（target）を予測する教師あり機械学習の練習として用いられます。

まずは、必要なライブラリをインポートします。
```python:ライブラリのインポート
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.neighbors import  KNeighborsClassifier
from sklearn.model_selection import train_test_split, KFold, cross_val_score
```
データセットを読み込みます。
```python:データセットの読み込み
# データセットの読み込み
cancer = load_breast_cancer()


X = cancer.data
y = cancer.target
```
乳がんかどうかを判定するために用いる __説明変数__ がXに格納され、実際に乳がんかどうかのデータである __目的変数__ がyに格納されます。次に、データセットを訓練用とテスト用に分割します。
```python:データセットの分割
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    stratify = cancer.target, 
    random_state=0)
```
`train_test_split`関数は、データセットを訓練用とテスト用に分割する関数です。`stratify`オプションには、目的変数を指定します。`random_state`オプションは、乱数のシードを指定します。これにより、実行するたびにデータセットが変わることを防ぎます。
:::message 
`stratify`オプションを設定すると、訓練データとテストデータで、目的変数の割合が同じになります。これにより、訓練データとテストデータの偏りを防ぐことができます。
:::
次に、グラフ描画用のリストを用意します。
```python:グラフ描画用のリストの用意
# グラフ描画用のリストを用意
training_accuracy = []
test_accuracy = []
score_list = []
```
今回は、k-NN（k近傍法）と呼ばれる手法を用いて、乳がんの判定を行う機械学習モデルを構築します。k-NNは、__訓練データの中から、最も近いk個のデータを参考に、テストデータのクラスを予測する__ 手法です。k-NNのモデルを構築するには、`KNeighborsClassifier`クラスを用います。
```python:k-NNのモデルの構築
neighbor_setting = range(1,21)
# 学習
for n_neighbors in neighbor_setting:
    model = KNeighborsClassifier(n_neighbors=n_neighbors)
    model.fit(X_train, y_train)
    training_accuracy.append(model.score(X_train, y_train))
    test_accuracy.append(model.score(X_test, y_test))
    cv = KFold(n_splits=5,random_state=0,shuffle=True)
    scores = cross_val_score(model,X,y,
              scoring="neg_mean_squared_error",cv=cv,n_jobs=-1)
    score_list.append(-np.mean(scores))
```
`n_neighbors`オプションで、kの値を指定しています。kの値によってモデルの精度が変化するため、どのkが最適かを交差検証により評価するコードです。

`fit`メソッドで、モデルを訓練します。`score`メソッドで、訓練データとテストデータの正解率を計算します。`cross_val_score`関数は、交差検証を行う関数です。交差検証とは、データセットを複数のグループに分割し、それぞれのグループを訓練用とテスト用に分けて、複数回の検証を行う手法です。`scoring`オプションで、評価指標を指定します。`cv`オプションで、分割数を指定します。`n_jobs`オプションで、並列処理を行うかどうかを指定します。`-1`を指定すると、CPUのコア数に応じて並列処理を行います。

最後に、訓練データとテストデータの正解率をグラフに描画します。
```python:グラフの描画
# グラフを描画
# 訓練データとテストデータの正解率をプロット
fig = plt.figure()
plt.plot(range(1, 21), training_accuracy, label='Training')
plt.plot(range(1, 21), test_accuracy, label='Test')
plt.xticks(neighbor_setting)
plt.xlabel('n_neighbors')
plt.ylabel('Accuracy')
plt.legend()
plt.show()


min_score = min(score_list)
min_n = score_list.index(min_score)+1

# 5-fold cv errorをプロット
fig = plt.figure()
plt.plot(neighbor_setting,score_list)
plt.scatter(min_n,min_score,label="min={}".format(min_n),c="red")
plt.xticks(neighbor_setting)
plt.xlabel("n_neighbors")
plt.title("Finding the Best n for k-NN: 5-Fold CV Error Analysis")
plt.ylabel("5fold cv error")
plt.legend()
plt.show()
```
![k-NN](/images/20231130/20231130_14.png =500x)
*訓練データとテストデータの正解率をプロット*
![k-NN](/images/20231130/20231130_15.png =500x)
*5-fold cv errorをプロット*

以上の結果から、k=9が最適であることがわかります。このように、Anacondaで導入されたツールを用いることで、事前準備なしに機械学習を行うことができます。